# Bayes判别
是一种基于数理统计的分类方法，将待判别的特征x（是一个向量）分类到条件概率最大的类别

应用的例子：https://zhuanlan.zhihu.com/p/82402288

## 最小错误率判别
这种方法下，简单地判断x来自于哪一个类的概率较大，即通过**后验概率**P(ω|x)的对比来进行判断（即，x发生的条件下ω发生的概率，ω是一个分类），认为x属于后验概率最大的那个分类。对于只有两个分类的情况下，可以用如下方法判别（推导过程略）：

$$
x \in \omega _{1} \space \space \space if \space \space \space l12(x)=\frac{p(x|\omega _{1})}{p(x|\omega _{2})}> \frac{p(\omega _{2})}{p(\omega _{1})}
$$

$$
x \in \omega _{2} \space \space \space if \space \space \space l12(x)=\frac{p(x|\omega _{1})}{p(x|\omega _{2})}< \frac{p(\omega _{2})}{p(\omega _{1})}
$$

不等式左边称为似然比，不等式右边称为判决阈值。

## 最小风险判别
一般都是通过这种加权后的方法执行

如果有M个类，当判定样本属于ω_j这个类时，计算**条件平均风险**如下所示：

$$
r_{j}(x)= \sum_{i=1}^{M}L_{ij}p(\omega _{i}|x)
$$

L_ij代表误判的代价，即“权重”，当i=j时，即判断正确，取0（或负数？）；当i!=j时，表示判断错误，取一个正值，值的大小取决于实际问题中代价的大小

判断时，取上式值**最小**（即风险最小）的一个类作为x所属的分类。
