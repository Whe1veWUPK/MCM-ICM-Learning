# 逐步回归
是一种**多元线性回归**的方法

图形界面分析工具：https://www.spsspro.com/

ps：一天8块，免费版只能分析100条数据

## 回归
回归分析是研究**自变量与因变量之间数量变化关系**的一种分析方法，它主要是通过因变量Y与影响它的自变量Xi（i1,2,3…）之间的回归模型，衡量自变量Xi对因变量Y的影响能力的，进而可以用来预测因变量Y的发展趋势。

## 线性回归

线性回归指每个自变量的**最高次项为1次**的回归问题

**适用条件**：
- 适用于回归问题，即要预测的变量y的取值集合是**无限且连续**的（相对应地，分类问题用来处理变量y的取值集合是有限、离散的）
- 变量之间必须是线性关系
- 误差服从均值为0的正态分布
- 数据的自变量x需要有足够大的分布范围（即，不能所有数据都只集中在一小部分定义域中）
- 不同特征（自变量）之间要**相互独立/线性无关**，否则会使模型不准确

**一般步骤**：
1. 构建线性方程

$$
y= \sum_{i=1}^{n}a_{i}x_{i}+ b
$$

2. 构造损失函数。典型的损失函数是平方误差，即预测值与实际值的差的平方和：

$$
L(a_{1},\cdots,a_{n},b)= \sum_{i=1}^{n}(f(x_{i})-y_{i})^{2}
$$

3. 确定参数a_i和b，一种常用的方法是**最小二乘法**（有图形界面实现，不用手打）

为了满足最后一个条件，可以事先对自变量进行相关性检验，但逐步回归方法可以解决这个问题。

## 逐步回归
逐步回归会把变量逐一引入并检验，剔除那些没有意义的变量，最后得到回归模型。

有三种**主要做法**：
- 向前选择forward：将自变量逐一引入，每引入一个自变量，对模型进行F检验，如果发生了显著性变化，则引入该变量，否则忽略。这种方法的**特点**是自变量一旦选入，则永远保存在模型中；不能反映自变量选进模型后的模型本身的变化情况。
- 向后选择backward：将所有变量放入模型，然后逐一尝试剔除，如果模型没有显著性变化则剔除，否则保留。与forward相对，自变量一旦剔除，则不再进入模型；开始把全部自变量引入模型，计算量过大。
- **逐步筛选法stepwise**（常用）：当引入一个变量后，首先查看这个变量是否使得模型发生显著性变化（F检验），若发生显著性变化，再对所有变量进行t检验，当原来引入变量由于后面加入的变量的引入而不再显著变化时，则剔除此变量，确保每次引入新的变量之前回归方程中只包含显著性变量，直到既没有显著的解释变量选入回归方程，也没有不显著的解释变量从回归方程中剔除为止，最终得到一个最优的变量集合。


**缺点**：
- 由于该方法按确定的顺序选择自变量，有可能会导致希望研究的核心变量被去除，而保留了另一个变量
- 一般需要较大的样本规模
